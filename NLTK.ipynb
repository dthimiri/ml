{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Taks in Natural Language Processing\n",
    "\n",
    "#### Breaking down text into words and sentences - TOKENIZATION\n",
    "#### Identifying the type of word [Noun, Verb etc.,] - PARTS-OF-SPEECH TAGGING\n",
    "#### Identifying commonly occuring words / group of words - FREQUENCY, N-grams\n",
    "#### Filtering common words such as 'The', 'A', 'AN' - STOPWORD REMOVAL\n",
    "#### Understanding the context in which a word occurs - WORD SENSE DISAMBIGUATION\n",
    "#### Reduce a word to its base form - STEMMING\n",
    "\n",
    "\n",
    "#### A large body of text, collections of news articles - CORPUS\n",
    "#### A dictionary / collection of dictionaries - LEXICAL RESOURCE\n",
    "\n",
    "\n",
    "\n",
    "### UNDERSTANDING THE CONTEXT OF A TEXT\n",
    "#### concordance() - Displays all occurances of a word along with context.\n",
    "#### similar() - Returns a list of words that appear in similar contexts - Usually synonyms\n",
    "#### common_contexts() - Returns contexts shared by 2 words\n",
    "#### dispersion_plot() - Prints a plot of all the occurances of the word relative to the beginning of the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Text\n",
    "\n",
    "#### sent_tokenize(), word_tokenize() - TOKENIZE TEXT INTO LISTS OF SENTENCES (OR) LISTS OF WORDS\n",
    "#### stopwords.words() - GET A LIST OF STOPWORDS - COMMONLY OCCURING WORDS\n",
    "#### bigrams(), ngrams() - GENERATE BIGRAMS [PAIRS OF WORDS] OR N-GRAMS [GROUPS OF N-WORDS] FOR A SENTENCE OR A TEXT\n",
    "#### collocations() - FIND THE MOST COMMONLY OCCURING BIGRAMS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/dilipthimiri/anaconda/lib/python3.6/site-packages\r\n",
      "Requirement already satisfied: six in /Users/dilipthimiri/anaconda/lib/python3.6/site-packages (from nltk)\r\n"
     ]
    }
   ],
   "source": [
    "# Import the nltk module\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nltk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-577c8c09cf72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Download the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'nltk' is not defined"
     ]
    }
   ],
   "source": [
    "# Download the dataset\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1.collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1.concordance(\"monstrous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2.concordance(\"monstrous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2.common_contexts([\"monstrous\", \"very\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" \".join (text4[:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets see how the usage of certain words by Presidents has changed over the years. \n",
    "\n",
    "text4.dispersion_plot([\"citizens\", \"democracy\", \"freedom\", \"duties\", \"America\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what kind of emotions are expressed in Jane Austen's works vs Herman Melville's\n",
    "text1.dispersion_plot([\"happy\", \"sad\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2.dispersion_plot([\"happy\", \"sad\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization\n",
    "# splitting a piece of text into sentences and words\n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "text =\"Mary had a little lamb. Her fleece was white as snow.\"\n",
    "sents = sent_tokenize(text)\n",
    "print(text)\n",
    "print(sents)\n",
    "\n",
    "words = [word_tokenize(sent) for sent in sents]\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out the stopwords and punctations\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "customStopWords = set(stopwords.words('english') + list(punctuation))\n",
    "wordsWOStopWords = [word for word in word_tokenize(text) if word not in customStopWords]\n",
    "wordsWOStopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemming - the process of removing morphological affixes from words, l\n",
    "# leaving only the word stem.\n",
    "\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "\n",
    "text2=\"Mary closed on closing night when she was in the mood to close.\"\n",
    "stemmer = LancasterStemmer()\n",
    "words = [x for x in word_tokenize(text2)]\n",
    "print(words)\n",
    "stemmedWords = [stemmer.stem(x) for x in word_tokenize(text2)]\n",
    "print(stemmedWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK has a functionality to automatically tag words as nouns, verbs, conjugation etc\n",
    "from nltk import pos_tag\n",
    "\n",
    "pt = pos_tag(word_tokenize(text2))\n",
    "\n",
    "wordParts = [pos_tag(word_tokenize(x)) for x in word_tokenize(text2) if x not in customStopWords]\n",
    "wordParts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
